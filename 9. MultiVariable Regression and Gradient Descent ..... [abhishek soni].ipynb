{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) more complex boundaries in linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading boston datasets\n",
      "shape of boston data is : (506, 13)\n",
      "\n",
      "making a dataframe of boston dataset for manipulation\n",
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "type of df.AGE is : <class 'pandas.core.series.Series'>\n",
      "type of df[AGE] is : <class 'pandas.core.series.Series'>\n",
      "df.AGE dtype is : float64\n",
      "shape of new boston data : (506, 14)\n",
      "\n",
      "testing.....\n",
      "train score of 1 : 0.7697699488741149\n",
      "train score of 2 : 0.7707245449911091\n",
      "test score of 1 : 0.6354638433202129\n",
      "test score of 2 : 0.6433109272342966\n"
     ]
    }
   ],
   "source": [
    "## loading boston datasets\n",
    "\n",
    "print(\"loading boston datasets\")\n",
    "from sklearn import datasets\n",
    "boston = datasets.load_boston()\n",
    "x = boston.data\n",
    "y = boston.target\n",
    "\n",
    "print(\"shape of boston data is :\" , x.shape)\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "## making a dataframe of boston dataset for manipulation\n",
    "\n",
    "print(\"making a dataframe of boston dataset for manipulation\")\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(x)\n",
    "print(boston.feature_names)\n",
    "df.columns = boston.feature_names\n",
    "df[\"age_age\"] = df.AGE ** 2\n",
    "\n",
    "print(\"type of df.AGE is :\" , type(df.AGE))\n",
    "print(\"type of df[\"\"AGE\"\"] is :\" , type(df[\"AGE\"]));\n",
    "print(\"df.AGE dtype is :\" , df.AGE.dtype)\n",
    "\n",
    "df.describe()\n",
    "x2 = df.values\n",
    "print(\"shape of new boston data :\" , x2.shape)\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "## split the datasets into trining and testing datasets\n",
    "\n",
    "from sklearn import model_selection\n",
    "x_train , x_test , y_train , y_test = model_selection.train_test_split(x , y , random_state = 0)\n",
    "x2_train , x2_test , y2_train , y2_test = model_selection.train_test_split(x2 , y , random_state = 0)\n",
    "\n",
    "\n",
    "\n",
    "## train your algorithm with training datasets\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "algo1 = LinearRegression()\n",
    "algo2 = LinearRegression()\n",
    "algo1.fit(x_train , y_train)\n",
    "algo2.fit(x2_train , y2_train)\n",
    "\n",
    "\n",
    "\n",
    "## test your algorithm\n",
    "\n",
    "print(\"testing.....\")\n",
    "\n",
    "train_score1 = algo1.score(x_train , y_train)\n",
    "test_score1 = algo1.score(x_test , y_test)\n",
    "train_score2 = algo2.score(x2_train , y2_train)\n",
    "test_score2 = algo2.score(x2_test , y2_test)\n",
    "\n",
    "print(\"train score of 1 :\" , train_score1)\n",
    "print(\"train score of 2 :\" , train_score2)\n",
    "print(\"test score of 1 :\" , test_score1)\n",
    "print(\"test score of 2 :\" , test_score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(points, m , c):\n",
    "    total_cost = 0\n",
    "    N = len(points)\n",
    "    for i in range(N):\n",
    "        x = points[i , 0]\n",
    "        y = points[i , 1]\n",
    "        total_cost += (1/N) * ((y - m * x - c) ** 2)\n",
    "    return total_cost\n",
    "\n",
    "\n",
    "def step_gradient(points , learning_rate , m , c):\n",
    "    m_slope = 0\n",
    "    c_slope = 0\n",
    "    N = len(points)\n",
    "    for i in range(N):\n",
    "        x = points[i , 0]\n",
    "        y = points[i , 1]\n",
    "        m_slope += (-2/N)*(y - m*x - c)*x\n",
    "        c_slope += (-2/N)*(y - m*x - c)\n",
    "    new_m = m - learning_rate * m_slope\n",
    "    new_c = c - learning_rate * c_slope\n",
    "    return new_m , new_c\n",
    "    \n",
    "    \n",
    "def gd(points , learning_rate , num_iteration):\n",
    "    m = 0\n",
    "    c = 0\n",
    "    for i in range(num_iteration):\n",
    "        m , c = step_gradient(points , learning_rate , m , c)\n",
    "        print(\"i :\" , i , \" cost :\" , cost(points , m , c))\n",
    "    return m , c\n",
    "\n",
    "def run():\n",
    "    data = np.loadtxt(\"data.csv\" , delimiter = \",\")\n",
    "    learning_rate = 0.0001\n",
    "    num_iteration = 38\n",
    "    m , c = gd(data , learning_rate , num_iteration)\n",
    "    print(m , c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i : 0  cost : 1484.5865574086486\n",
      "i : 1  cost : 457.8542575737672\n",
      "i : 2  cost : 199.5099857255389\n",
      "i : 3  cost : 134.50591058200533\n",
      "i : 4  cost : 118.1496934223995\n",
      "i : 5  cost : 114.0341490603815\n",
      "i : 6  cost : 112.99857731713657\n",
      "i : 7  cost : 112.73798187568467\n",
      "i : 8  cost : 112.6723843590911\n",
      "i : 9  cost : 112.65585181499745\n",
      "i : 10  cost : 112.65166489759581\n",
      "i : 11  cost : 112.6505843615011\n",
      "i : 12  cost : 112.65028544701502\n",
      "i : 13  cost : 112.65018320293967\n",
      "i : 14  cost : 112.650130445072\n",
      "i : 15  cost : 112.65009013922885\n",
      "i : 16  cost : 112.6500529669463\n",
      "i : 17  cost : 112.65001658353178\n",
      "i : 18  cost : 112.64998039901865\n",
      "i : 19  cost : 112.64994426496071\n",
      "i : 20  cost : 112.64990814400622\n",
      "i : 21  cost : 112.64987202675677\n",
      "i : 22  cost : 112.64983591084761\n",
      "i : 23  cost : 112.64979979568368\n",
      "i : 24  cost : 112.64976368111523\n",
      "i : 25  cost : 112.64972756710469\n",
      "i : 26  cost : 112.64969145364236\n",
      "i : 27  cost : 112.64965534072611\n",
      "i : 28  cost : 112.64961922835512\n",
      "i : 29  cost : 112.64958311652944\n",
      "i : 30  cost : 112.64954700524868\n",
      "i : 31  cost : 112.64951089451318\n",
      "i : 32  cost : 112.64947478432279\n",
      "i : 33  cost : 112.64943867467744\n",
      "i : 34  cost : 112.64940256557728\n",
      "i : 35  cost : 112.64936645702221\n",
      "i : 36  cost : 112.64933034901203\n",
      "i : 37  cost : 112.64929424154704\n",
      "1.4788759106351557 0.03135102019557585\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Generic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) stochatic and mini batch gradient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to do"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
