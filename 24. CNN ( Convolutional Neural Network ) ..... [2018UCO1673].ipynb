{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-0c9ecfd2ca0f>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\" , one_hot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) initializing weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_width = 28 \n",
    "input_height = 28\n",
    "input_channels = 1\n",
    "input_pixels = 784\n",
    "\n",
    "n_conv1 = 32\n",
    "n_conv2 = 64\n",
    "stride_conv1 = 1\n",
    "stride_conv2 = 1\n",
    "conv1_k = 5\n",
    "conv2_k = 5\n",
    "max_pool1_k = 2\n",
    "max_pool2_k = 2\n",
    "\n",
    "n_hidden = 1024 # of units\n",
    "n_out = 10      # ofunits\n",
    "\n",
    "input_size_to_hidden = (input_width // (max_pool1_k * max_pool2_k)) * (input_height // (max_pool1_k * max_pool2_k)) * n_conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    \"wc1\" : tf.Variable(tf.random_normal([conv1_k , conv1_k , input_channels , n_conv1])),\n",
    "    \"wc2\" : tf.Variable(tf.random_normal([conv2_k , conv2_k , n_conv1 , n_conv2])) ,\n",
    "    \"wh1\" : tf.Variable(tf.random_normal([input_size_to_hidden , n_hidden])) ,\n",
    "    \"wo\"  : tf.Variable(tf.random_normal([n_hidden , n_out]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"bc1\" : tf.Variable(tf.random_normal([n_conv1])) , \n",
    "    \"bc2\" : tf.Variable(tf.random_normal([n_conv2])) , \n",
    "    \"bh1\" : tf.Variable(tf.random_normal([n_hidden])) , \n",
    "    \"bo\" : tf.Variable(tf.random_normal([n_out]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(x , weights , bias , strides = 1):\n",
    "    out = tf.nn.conv2d(x , weights , padding = \"SAME\" , strides = [1 , strides , strides , 1])\n",
    "    out = tf.nn.bias_add(out , bias)\n",
    "    out = tf.nn.relu(out)\n",
    "    return out\n",
    "\n",
    "def maxpooling(x , k = 2):\n",
    "    return tf.nn.max_pool(x , padding = \"SAME\" , ksize = [1 , k , k , 1] , strides = [1 , k , k , 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward\n",
    "def cnn(x , weights , biases , keep_prob):\n",
    "    ## -1 is for infer the size , it will automatically fill the first size\n",
    "    x = tf.reshape(x , shape = [ -1 , input_height , input_width , input_channels])\n",
    "        \n",
    "    ## cnn part .....\n",
    "    conv1 = conv(x , weights[\"wc1\"] , biases[\"bc1\"] , stride_conv1)\n",
    "    conv1_pool = maxpooling(conv1 , max_pool1_k)\n",
    "    \n",
    "    conv2 = conv(conv1_pool , weights[\"wc2\"] , biases[\"bc2\"] , stride_conv2)\n",
    "    conv2_pool = maxpooling(conv2 , max_pool2_k)\n",
    "    \n",
    "    ## reshape to original format\n",
    "    hidden_input = tf.reshape(conv2_pool ,shape = [-1 , input_size_to_hidden])\n",
    "    hidden_output_before_activation = tf.add(tf.matmul(hidden_input , weights[\"wh1\"]) , biases[\"bh1\"])\n",
    "    hidden_output_before_dropout = tf.nn.relu(hidden_output_before_activation)\n",
    "    hidden_output = tf.nn.dropout(hidden_output_before_dropout , keep_prob)\n",
    "    output = tf.add(tf.matmul(hidden_output , weights[\"wo\"]) , biases[\"bo\"])\n",
    "    \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-474edaa58421>:17: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(\"float\", [None, input_pixels])\n",
    "y = tf.placeholder(tf.int32, [None, n_out])\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "pred = cnn(x, weights, biases, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels = y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimize = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901789.399493888\n",
      "40219.36001363397\n",
      "23956.219490707444\n",
      "16349.599766741274\n",
      "11257.720092945483\n",
      "10140.574692701013\n",
      "9217.12903651474\n",
      "9513.836469548485\n",
      "6310.271248396497\n",
      "5461.271398638338\n",
      "5901.799012111947\n",
      "5251.687190786591\n",
      "4439.914180814047\n",
      "4540.2383428836965\n",
      "4563.3356049115255\n",
      "3689.811675340212\n",
      "3045.699203925539\n",
      "2913.088819910705\n",
      "2797.5322378471833\n",
      "2424.6886386664305\n",
      "2948.518144794079\n",
      "2493.4562018529277\n",
      "1769.5681861084283\n",
      "2487.770146941719\n",
      "2037.0781651122234\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "for i in range(25):\n",
    "    num_batches = int(mnist.train.num_examples/batch_size)\n",
    "    total_cost = 0\n",
    "    for j in range(num_batches):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        c, _ = sess.run([cost,optimize], feed_dict={x:batch_x , y:batch_y, keep_prob:0.8})\n",
    "        total_cost += c\n",
    "    print(total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9850"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = tf.argmax(pred , 1)\n",
    "correct_labels = tf.argmax(y , 1)\n",
    "correct_predictions = tf.equal(predictions , correct_labels)\n",
    "predictions , correct_preds = sess.run([predictions , correct_predictions] , feed_dict = {\n",
    "    x : mnist.test.images ,\n",
    "    y : mnist.test.labels ,\n",
    "    keep_prob : 1.0\n",
    "})\n",
    "correct_preds.sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "effect of providing 0 keep probability to the dropout layer in case of tensorflow === >>> WILL ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Adding dropout Layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
