{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow\n",
    "TensorFlow is an open-source software library for dataflow programming across a range of tasks. It is a symbolic math library, and is also used for machine learning applications such as neural networks. It is used for both research and production at Google, often replacing its closed-source predecessor, DistBelief.\n",
    "\n",
    "TensorFlow computations are expressed as stateful dataflow graphs. The name TensorFlow derives from the operations that such neural networks perform on multidimensional data arrays. These arrays are referred to as \"tensors\". In June 2016, Dean stated that 1,500 repositories on GitHub mentioned TensorFlow, of which only 5 were from Google.\n",
    "\n",
    "TensorFlow is cross-platform. It runs on nearly everything: GPUs and CPUs—including mobile and embedded platforms—and even tensor processing units (TPUs), which are specialized hardware to do tensor math on.\n",
    "\n",
    "![title](1tensorflow.png)\n",
    "\n",
    "\n",
    "The TensorFlow distributed execution engine abstracts away the many supported devices and provides a high performance-core implemented in C++ for the TensorFlow platform.\n",
    "On top of that sit the Python and C++ frontends (with more to come). The Layers API provides a simpler interface for commonly used layers in deep learning models. On top of that sit higher-level APIs, including Keras (more on the Keras.io site) and the Estimator API, which makes training and evaluating distributed models easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) How to install and Import Tensorflow ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "## Commands to install tensorflow\n",
    "# 1. conda install tensorflow\n",
    "# 2. conda install tensorflow-gpu\n",
    "# 3. pip install tensorflow ( run anaconda prompt as administration)\n",
    "\n",
    "## tensorflow has basically 2 version v1 , v2\n",
    "\n",
    "## version 1\n",
    "import tensorflow as tf\n",
    "## to install version go to anaconda navigator after completing the above steps \n",
    "## and change tenserflow version to 1.5.0\n",
    "## keras version to 2.3.1\n",
    "\n",
    "## version v2\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()\n",
    "\n",
    "# ## to remove the message warning from version 2\n",
    "# import tensorflow.python.util.deprecation as deprecation\n",
    "# deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Const:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'Const_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'add:0' shape=() dtype=int32>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(2) ## it is Tensor type of an object\n",
    "b = tf.constant(3)\n",
    "c = a + b\n",
    "a , b , c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5, numpy.int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "c_val , a_val = sess.run(c) , sess.run(a)\n",
    "a_val , c_val , type(a_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = tf.constant([[3 , 3]])\n",
    "a2 = tf.constant([[3] , [3]])\n",
    "a3 = tf.matmul(a1 , a2)\n",
    "## we can't change the value of constant once it assign\n",
    "sess.run(a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_5:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(1)\n",
    "a = tf.constant(2)\n",
    "## Here we aren’t changing the constant, we have created another constant with different value. \n",
    "## Python variable a is not a constant.\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n",
    "c = a + b\n",
    "c = tf.add(a , c)\n",
    "# print(c.eval()) ## there is no default session\n",
    "with tf.Session() as sess:\n",
    "    ## this sess object will work within this block\n",
    "    print(c.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1 = tf.Variable(100) ## right now it is an un - initialize variable\n",
    "var2 = tf.Variable(3)\n",
    "sum = tf.add(var1 , var2)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) ## it is use to make all variable global and to initialize them \n",
    "sess.run(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "103\n",
      "1232\n",
      "1235\n"
     ]
    }
   ],
   "source": [
    "assign = var1.assign(1232)\n",
    "print(sess.run(var1))\n",
    "print(sess.run(sum))\n",
    "sess.run(assign)\n",
    "print(sess.run(var1))\n",
    "print(sess.run(sum))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "var1 = tf.Variable(100)\n",
    "sess= tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "assign = var1.assign(12.32)\n",
    "sess.run(assign)\n",
    "\n",
    "# ERROR !!!!!!!!!!!!\n",
    "\n",
    "# var1 was supposed to have int32 value but 12.32 which is float was passed, # # hence error ."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "var1 = tf.Variable(100)\n",
    "var2 = tf.Variable(200)\n",
    "sess= tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "var3 = tf.Variable(300)\n",
    "sess.run(var3)\n",
    "\n",
    "\n",
    "# ERROR !!!!!!!!!!!!!!!\n",
    "\n",
    "# Variable initializers must be run explicitly before other ops in your model  # can be run. Since var3 was not initialized (as it is written after global    # variable initializer) it created error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 24, 36],\n",
       "       [48, 60, 72]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.int32 , shape = (2 , 3)) ## by default it is shape = ()\n",
    "y = x * tf.constant(12)\n",
    "# sess.run(y) ## give error!!!!!\n",
    "sess.run(y , feed_dict = {x : [[1 , 2 , 3] , [4 , 5 , 6]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) MNIST "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Load the data.........."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##  given a image which contains 1 to 9 digit we have to build a classifier \n",
    "##  to predict what no is written on the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\" , one_hot = True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# from sklearn.datasets import fetch_mldata \n",
    "# mnist = fetch_mldata('MNIST original', data_home=custom_data_home) \n",
    "# ## will fetch the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x00000256D2735D08>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x00000256D035A908>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x00000256D001AE08>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 784), (55000, 10))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape , mnist.train.labels.shape\n",
    "## there are total 55000 flaten images and each images os of dimesion 28 x 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels[0] ## labels are hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), (10000, 10))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape , mnist.test.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.validation.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "first_image = mnist.train.images[412]\n",
    "first_image = np.array(first_image , dtype = 'float')\n",
    "first_image = first_image.reshape((28 , 28))\n",
    "plt.imshow(first_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.6934016e+00 -9.0782458e-01 -4.8745263e-02 ...  2.3526177e-01\n",
      "  -6.7758274e-01  1.1348503e+00]\n",
      " [-1.8062690e-02 -9.1168389e-02  5.8441508e-01 ... -3.0736681e-02\n",
      "   2.7564251e+00  1.7175034e+00]\n",
      " [-7.8653109e-01  7.3506099e-01  3.0115053e-01 ... -3.9780074e-01\n",
      "   6.7218584e-01 -9.0632629e-01]\n",
      " ...\n",
      " [-9.4026989e-01 -1.0638218e+00  3.7405476e-01 ... -6.7937925e-02\n",
      "   1.9021906e-01 -1.5895494e+00]\n",
      " [-3.5777003e-01  7.1384907e-01  5.6214648e-01 ... -3.6530498e-01\n",
      "  -7.4618231e-03  7.4879575e-01]\n",
      " [ 8.6005408e-01 -2.5310557e-02 -8.8476193e-01 ...  1.4269655e-03\n",
      "  -6.2718534e-01  2.5962923e-02]]\n"
     ]
    }
   ],
   "source": [
    "## random_normal\n",
    "with tf.Session() as sess:\n",
    "    print(tf.random_normal([784 , 256]).eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Intialising weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256\n",
    "n_classes = 10\n",
    "\n",
    "weights = {\n",
    "    \"h1\" : tf.Variable(tf.random_normal([n_input , n_hidden_1]) ) ,\n",
    "#     \"h1\" : tf.Variable(tf.random_normal([n_input , n_hidden_1]) , trainable = False) ,\n",
    "    \"h2\" : tf.Variable(tf.random_normal([n_hidden_1 , n_hidden_2])) ,\n",
    "    \"out\" : tf.Variable(tf.random_normal([n_hidden_2 , n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"h1\" : tf.Variable(tf.random_normal([n_hidden_1])) , \n",
    "    \"h2\" : tf.Variable(tf.random_normal([n_hidden_2])) , \n",
    "    \"out\" : tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=() dtype=int32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=() dtype=int32_ref>,\n",
       " <tf.Variable 'Variable_2:0' shape=(784, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_3:0' shape=(256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_4:0' shape=(256, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_5:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_6:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_7:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(x , weights , biases):\n",
    "    in_layer1 = tf.add(tf.matmul(x , weights[\"h1\"]) , biases[\"h1\"])\n",
    "    out_layer1 = tf.nn.relu(in_layer1)\n",
    "    \n",
    "    in_layer2 = tf.add(tf.matmul(out_layer1 , weights[\"h2\"]) , biases[\"h2\"])\n",
    "    out_layer2 = tf.nn.relu(in_layer2)\n",
    "    \n",
    "    output = tf.add(tf.matmul(out_layer2 , weights[\"out\"]) , biases[\"out\"])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Having identity activation function on all layers will lead to we learning linear decision boundary. \n",
    "In most problems that would lead to worse results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) finding the prediction and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "x = tf.placeholder(\"float\" , [None , n_input])\n",
    "y = tf.placeholder(tf.int32 , [None , n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 5, ..., 5, 5, 5], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predicted output\n",
    "pred = forward_propagation(x , weights , biases)\n",
    "predictions = tf.argmax(pred , 1)\n",
    "predictions_eval = sess.run(predictions , feed_dict = {x : mnist.test.images})\n",
    "predictions_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## actual labels\n",
    "true_labels = tf.argmax(y , 1)\n",
    "labels = sess.run(true_labels , feed_dict = {y : mnist.test.labels})\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## correct prediction\n",
    "correct_predictions = tf.equal(predictions , true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4, 5, 5, ..., 5, 5, 5], dtype=int64),\n",
       " array([7, 2, 1, ..., 4, 5, 6], dtype=int64),\n",
       " array([False, False, False, ..., False,  True, False]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## other way to run simultanously\n",
    "predictions_eval , labels , correct_pred = sess.run([predictions , true_labels , correct_predictions] , feed_dict = {x : mnist.test.images , y : mnist.test.labels})\n",
    "predictions_eval , labels , correct_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1005"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## how many we are getting correct\n",
    "correct_pred.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-27-b845cf64bfb6>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## cross entropy function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred , labels = y))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2075.6528"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(cost , feed_dict = {x : mnist.train.images , y : mnist.train.labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Running the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "[<tf.Variable 'Variable:0' shape=() dtype=int32_ref>, <tf.Variable 'Variable_1:0' shape=() dtype=int32_ref>, <tf.Variable 'Variable_2:0' shape=(784, 256) dtype=float32_ref>, <tf.Variable 'Variable_3:0' shape=(256, 256) dtype=float32_ref>, <tf.Variable 'Variable_4:0' shape=(256, 10) dtype=float32_ref>, <tf.Variable 'Variable_5:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'Variable_6:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'Variable_7:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_8:0' shape=(784, 256) dtype=float32_ref>, <tf.Variable 'Variable_9:0' shape=(256, 256) dtype=float32_ref>, <tf.Variable 'Variable_10:0' shape=(256, 10) dtype=float32_ref>, <tf.Variable 'Variable_11:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'Variable_12:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'Variable_13:0' shape=(10,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\" , one_hot = True)\n",
    "\n",
    "n_input = 784\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256\n",
    "n_classes = 10\n",
    "\n",
    "weights = {\n",
    "    \"h1\" : tf.Variable(tf.random_normal([n_input , n_hidden_1]) ) ,\n",
    "    \"h2\" : tf.Variable(tf.random_normal([n_hidden_1 , n_hidden_2])) ,\n",
    "    \"out\" : tf.Variable(tf.random_normal([n_hidden_2 , n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"h1\" : tf.Variable(tf.random_normal([n_hidden_1])) , \n",
    "    \"h2\" : tf.Variable(tf.random_normal([n_hidden_2])) , \n",
    "    \"out\" : tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "print(tf.trainable_variables())\n",
    "\n",
    "def forward_propagation(x , weights , biases):\n",
    "    in_layer1 = tf.add(tf.matmul(x , weights[\"h1\"]) , biases[\"h1\"])\n",
    "    out_layer1 = tf.nn.relu(in_layer1)\n",
    "    \n",
    "    in_layer2 = tf.add(tf.matmul(out_layer1 , weights[\"h2\"]) , biases[\"h2\"])\n",
    "    out_layer2 = tf.nn.relu(in_layer2)\n",
    "    \n",
    "    output = tf.add(tf.matmul(out_layer2 , weights[\"out\"]) , biases[\"out\"])\n",
    "    return output\n",
    "\n",
    "x = tf.placeholder(\"float\" , [None , n_input])\n",
    "y = tf.placeholder(tf.int32 , [None , n_classes])\n",
    "pred = forward_propagation(x , weights , biases)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred , labels = y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate =  0.01)\n",
    "optimize = optimizer.minimize(cost)\n",
    "\n",
    "# minimize function ===>> finds the derivative(slope) values & chnage the values as per the learning rate\n",
    "# and the slopes once\n",
    "## if there is no variable which are trainable then this will give error \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3064.2747\n"
     ]
    }
   ],
   "source": [
    "c, _ = sess.run([cost,optimize], feed_dict = {x:mnist.train.images , y:mnist.train.labels})\n",
    "print(c)\n",
    "## every time we run it it will reduce the cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g) How does the optimizer work ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=() dtype=int32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=() dtype=int32_ref>,\n",
       " <tf.Variable 'Variable_2:0' shape=(784, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_3:0' shape=(256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_4:0' shape=(256, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_5:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_6:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_7:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_8:0' shape=(784, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_9:0' shape=(256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_10:0' shape=(256, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_11:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_12:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_13:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## first it will find which variables depends upon cost function and trainable = True\n",
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h) running multiple iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1591.4557\n",
      "1227.6194\n",
      "956.62146\n",
      "790.42633\n",
      "700.2512\n",
      "636.4966\n",
      "568.115\n",
      "475.92465\n",
      "378.05542\n",
      "296.64307\n",
      "240.86438\n",
      "206.59113\n",
      "182.51486\n",
      "160.35391\n",
      "140.54857\n",
      "127.025154\n",
      "121.070435\n",
      "120.36418\n",
      "121.24138\n",
      "120.207275\n",
      "115.38292\n",
      "106.99047\n",
      "96.912346\n",
      "87.21384\n",
      "79.208916\n"
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    c , _ = sess.run([cost , optimize] , feed_dict = {x : mnist.train.images , y : mnist.train.labels})\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8373"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = tf.argmax(pred , 1)\n",
    "correct_labels = tf.argmax(y , 1)\n",
    "correct_predictions = tf.equal(predictions , correct_labels)\n",
    "predictions , correct_predictions = sess.run([predictions , correct_predictions] , feed_dict = {x : mnist.test.images , y : mnist.test.labels})\n",
    "\n",
    "correct_predictions.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Batch gradient descent"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "benefit of calling optimize in multiple batches :\n",
    "    it will be faster to reach the results\n",
    "    it will not reach better results irrespective of number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13997.194191714632\n",
      "4180.954490777254\n",
      "2471.177090359046\n",
      "1591.5871947667051\n",
      "1420.5042736675387\n",
      "1265.8064440161677\n",
      "1001.3624152433226\n",
      "892.8727606200329\n",
      "868.5923013933949\n",
      "805.130439615462\n",
      "701.7107965899795\n",
      "585.714692180202\n",
      "543.4623756766878\n",
      "466.0597000812766\n",
      "447.07890364921445\n",
      "382.8270943195958\n",
      "397.6262068239175\n",
      "344.5137250860313\n",
      "324.015757872116\n",
      "287.97091303172056\n",
      "273.14831460513926\n",
      "233.50156650033304\n",
      "184.49188855835666\n",
      "189.29186070472545\n",
      "183.6027430960331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9621"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "for i in range(25):\n",
    "    num_batches = int(mnist.train.num_examples / batch_size)\n",
    "    total_cost = 0\n",
    "    for j in range(num_batches):\n",
    "        batch_x , batch_y = mnist.train.next_batch(batch_size)\n",
    "        c , _ = sess.run([cost ,optimize] , feed_dict = {x : batch_x , y : batch_y})\n",
    "        total_cost += c\n",
    "    print(total_cost)\n",
    "    \n",
    "predictions = tf.argmax(pred , 1)\n",
    "correct_labels = tf.argmax(y , 1)\n",
    "correct_predictions = tf.equal(predictions , correct_labels)\n",
    "predictions , correct_predictions = sess.run([predictions , correct_predictions] , feed_dict = {x : mnist.test.images , y : mnist.test.labels})\n",
    "\n",
    "correct_predictions.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
